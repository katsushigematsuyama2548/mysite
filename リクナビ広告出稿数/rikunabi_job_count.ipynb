{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2661b7e8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import csv\n",
    "import time\n",
    "from typing import List\n",
    "from tqdm.notebook import tqdm\n",
    "from bs4 import BeautifulSoup\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.common.exceptions import NoSuchElementException\n",
    "import pandas as pd\n",
    "\n",
    "# WebDriverの設定\n",
    "driver_path = \"\\\\Users\\\\katus\\\\テスト\\\\chromedriver.exe\"\n",
    "chrome_options = Options()\n",
    "chrome_options.binary_location = \"C:\\\\Program Files\\\\Google\\\\Chrome\\\\Application\\\\chrome.exe\"\n",
    "service = Service(driver_path)\n",
    "browser = webdriver.Chrome(service=service, options=chrome_options)\n",
    "\n",
    "# CSVファイルから企業ページURLを読み込む\n",
    "with tqdm(total=3) as pbar:\n",
    "    with open('リクナビNEXT企業ページURL.csv', 'r') as csvfile:\n",
    "        reader = csv.reader(csvfile)\n",
    "        next(reader)  # ヘッダー行をスキップ\n",
    "\n",
    "        for _ in range(3):\n",
    "            row = next(reader)\n",
    "            if not row:\n",
    "                break\n",
    "\n",
    "            company_id = row[0]\n",
    "            url = f'https://next.rikunabi.com{company_id}'\n",
    "            job_count = []\n",
    "\n",
    "            # 企業ページを開く\n",
    "            browser.get(url)\n",
    "            time.sleep(3)  # ページ読み込み待ち\n",
    "\n",
    "            # 情報取得用のリストを初期化\n",
    "            company_value = []\n",
    "            industry_value = []\n",
    "            address_value = []\n",
    "\n",
    "            # ページのHTMLを取得し、BeautifulSoupで解析\n",
    "            html = browser.page_source\n",
    "            soup = BeautifulSoup(html, 'html.parser')\n",
    "\n",
    "            try:\n",
    "                # ログインボタンをクリックして企業情報を取得\n",
    "                elem_login_btn = browser.find_element(By.XPATH, '/html/body/div[4]/div[1]/div[1]/div/div[2]/ul/li[1]/div[3]/div/div[2]/div/div[1]/a').click()\n",
    "            except NoSuchElementException:\n",
    "                elem_login_btn = browser.find_element(By.XPATH, '/html/body/div[4]/div[1]/div[2]/div/div[2]/ul/li/div[1]/h2/a').click()\n",
    "                time.sleep(3)\n",
    "                browser.switch_to.window(browser.window_handles[1])\n",
    "\n",
    "            # 企業名を取得\n",
    "            company_name_element = browser.find_element(By.CSS_SELECTOR, \"p.rnn-offerCompanyName\")\n",
    "            company_name = company_name_element.text.strip()\n",
    "            company_value.append(company_name)\n",
    "\n",
    "            # 業種を取得\n",
    "            industry_element = browser.find_element(By.XPATH, \"//th[text()='業種']/following-sibling::td/p\")\n",
    "            industry = industry_element.text.strip().split('/')[0]\n",
    "            industry_value.append(industry)\n",
    "\n",
    "            # 連絡先を取得\n",
    "            contact_element = browser.find_element(By.XPATH, \"//th[text()='連絡先']/following-sibling::td/p\")\n",
    "            contact = contact_element.text.strip()\n",
    "            address_value.append(contact)\n",
    "\n",
    "            # データを辞書に格納し、リストに追加\n",
    "            data = {\n",
    "                \"company_name\": company_value,\n",
    "                \"industry\": industry_value,\n",
    "                \"address\": address_value,\n",
    "                \"jobcount\": job_count\n",
    "            }\n",
    "            all_data.append(data)\n",
    "\n",
    "            # ブラウザを閉じてメインウィンドウに戻る\n",
    "            browser.close()\n",
    "            browser.switch_to.window(browser.window_handles[0])\n",
    "            pbar.update(1)\n",
    "\n",
    "# 取得したデータをDataFrameに変換してCSV出力\n",
    "df = pd.DataFrame(all_data)\n",
    "df['company_name'] = df['company_name'].apply(lambda x: x[0] if isinstance(x, list) and len(x) > 0 else \"\")\n",
    "df['industry'] = df['industry'].apply(lambda x: x[0] if isinstance(x, list) and len(x) > 0 else \"\")\n",
    "df['address'] = df['address'].apply(lambda x: x[0] if isinstance(x, list) and len(x) > 0 else \"\")\n",
    "df['jobcount'] = df['jobcount'].apply(lambda x: x[0] if isinstance(x, list) and len(x) > 0 else \"\")\n",
    "df.to_csv('20240326.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a5cca88",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8401e520-dcb8-4120-a7cb-0ecb42548ab6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82244d8d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5924ca5e-6baf-4943-a6c7-343ccdf85b1f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0721f3a-fb41-42c9-9f67-1474013820d6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
